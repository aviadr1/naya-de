{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a SparkSession object can perform the most common data processing tasks\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "spark = SparkSession.builder.appName('test').getOrCreate() # will return existing session if one was\n",
    "                                                           # created before and was not closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
      "|Age|Sex|ChestPainType|RestingBP|Cholesterol|FastingBS|RestingECG|MaxHR|ExerciseAngina|Oldpeak|ST_Slope|HeartDisease|\n",
      "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
      "| 40|  M|          ATA|      140|        289|        0|    Normal|  172|             N|    0.0|      Up|           0|\n",
      "| 49|  F|          NAP|      160|        180|        0|    Normal|  156|             N|    1.0|    Flat|           1|\n",
      "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----+---+\n",
      "|older|age|\n",
      "+-----+---+\n",
      "| true| 40|\n",
      "| true| 49|\n",
      "+-----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let PySpark infer the schema\n",
    "df = spark.read.csv('heart.csv', inferSchema=True, header=True)\n",
    "\n",
    "# run an SQL query on the data\n",
    "df.createOrReplaceTempView(\"df\") # tell PySpark how the table will be called in the SQL query\n",
    "spark.sql(\"\"\"SELECT * from df\"\"\").show(2)\n",
    "\n",
    "# we also choose columns using SQL sytnx, with a command that combins '.select()' and '.sql()'\n",
    "df.selectExpr(\"age >= 40 as older\", \"age\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "x = spark.sql(\"\"\"SELECT COUNT(*) from df\"\"\").collect()[0][0]\n",
    "print(x, type(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# your turn\n",
    "\n",
    "use spark.sql() to perform the following actions\n",
    "1. get the max and min cholesterol\n",
    "2. group by ChestPainType and get the mean Cholesterol\n",
    "3. how many incidents of each ChestPainType for each sex?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[], functions=[min(Cholesterol#507), max(Cholesterol#507)])\n",
      "+- Exchange SinglePartition\n",
      "   +- *(1) HashAggregate(keys=[], functions=[partial_min(Cholesterol#507), partial_max(Cholesterol#507)])\n",
      "      +- *(1) FileScan csv [Cholesterol#507] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/naya/notebooks/05_spark/02_dataframes/heart.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Cholesterol:int>\n",
      "DataFrame[min(Cholesterol): int, max(Cholesterol): int]\n",
      "+----------------+----------------+\n",
      "|min(Cholesterol)|max(Cholesterol)|\n",
      "+----------------+----------------+\n",
      "|               0|             603|\n",
      "+----------------+----------------+\n",
      "\n",
      "0 603\n",
      "+----------------+----------------+\n",
      "|min(Cholesterol)|max(Cholesterol)|\n",
      "+----------------+----------------+\n",
      "|               0|             603|\n",
      "+----------------+----------------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[], functions=[min(Cholesterol#507), max(Cholesterol#507)])\n",
      "+- Exchange SinglePartition\n",
      "   +- *(1) HashAggregate(keys=[], functions=[partial_min(Cholesterol#507), partial_max(Cholesterol#507)])\n",
      "      +- *(1) FileScan csv [Cholesterol#507] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/naya/notebooks/05_spark/02_dataframes/heart.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Cholesterol:int>\n",
      "+----------------+----------------+\n",
      "|min(Cholesterol)|max(Cholesterol)|\n",
      "+----------------+----------------+\n",
      "|               0|             603|\n",
      "+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 1 get the max and min cholesterol\n",
    "\n",
    "# solution A (with spark.sql)\n",
    "answer = spark.sql(\"\"\"SELECT MIN(Cholesterol), MAX(Cholesterol) from df\"\"\")\n",
    "answer.explain()\n",
    "print(answer) # the answer is somewhere out there\n",
    "answer.show()  # this is the action\n",
    "min_, max_ = answer.collect()[0]\n",
    "print(min_, max_)\n",
    "\n",
    "# solution B (with selectExpr)\n",
    "df.selectExpr(\"MIN(Cholesterol)\", \"MAX(Cholesterol)\").show()\n",
    "\n",
    "# solution C (with pyspark dataframes: select and F.min and F.max)\n",
    "answer = df.select(F.min(\"Cholesterol\"), F.max(\"Cholesterol\"))\n",
    "answer.explain()\n",
    "answer.show()  # this is the action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|ChestPainType|  avg(Cholesterol)|\n",
      "+-------------+------------------+\n",
      "|          NAP| 197.4384236453202|\n",
      "|          ATA|233.04624277456648|\n",
      "|           TA|207.06521739130434|\n",
      "|          ASY| 186.6451612903226|\n",
      "+-------------+------------------+\n",
      "\n",
      "+-------------+------------------+\n",
      "|ChestPainType|  avg(Cholesterol)|\n",
      "+-------------+------------------+\n",
      "|          NAP| 197.4384236453202|\n",
      "|          ATA|233.04624277456648|\n",
      "|           TA|207.06521739130434|\n",
      "|          ASY| 186.6451612903226|\n",
      "+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### 2. group by ChestPainType and get the mean Cholesterol\n",
    "\n",
    "# Solution A (with spark.sql)\n",
    "spark.sql(\"\"\"SELECT ChestPainType, AVG(Cholesterol) from df GROUP BY ChestPainType\"\"\").show()\n",
    "\n",
    "\n",
    "# Solution B (with dataframes)\n",
    "df.groupBy(\"ChestPainType\").mean(\"Cholesterol\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|sex|count(ChestPainType)|\n",
      "+---+--------------------+\n",
      "|  F|                 193|\n",
      "|  M|                 725|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. how many incidents of each ChestPainType for each sex?\n",
    "spark.sql(\"\"\"\n",
    "    SELECT sex, COUNT(ChestPainType)\n",
    "    FROM df\n",
    "    GROUP BY sex\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
