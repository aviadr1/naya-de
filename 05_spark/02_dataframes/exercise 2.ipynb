{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a SparkSession object can perform the most common data processing tasks\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "spark = SparkSession.builder.appName('test').getOrCreate() # will return existing session if one was\n",
    "                                                           # created before and was not closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
      "|Age|Sex|ChestPainType|RestingBP|Cholesterol|FastingBS|RestingECG|MaxHR|ExerciseAngina|Oldpeak|ST_Slope|HeartDisease|\n",
      "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
      "| 40|  M|          ATA|      140|        289|        0|    Normal|  172|             N|    0.0|      Up|           0|\n",
      "| 49|  F|          NAP|      160|        180|        0|    Normal|  156|             N|    1.0|    Flat|           1|\n",
      "+---+---+-------------+---------+-----------+---------+----------+-----+--------------+-------+--------+------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+-----+---+\n",
      "|older|age|\n",
      "+-----+---+\n",
      "| true| 40|\n",
      "| true| 49|\n",
      "+-----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let PySpark infer the schema\n",
    "df = spark.read.csv('heart.csv', inferSchema=True, header=True)\n",
    "\n",
    "# run an SQL query on the data\n",
    "df.createOrReplaceTempView(\"df\") # tell PySpark how the table will be called in the SQL query\n",
    "spark.sql(\"\"\"SELECT * from df\"\"\").show(2)\n",
    "\n",
    "# we also choose columns using SQL sytnx, with a command that combins '.select()' and '.sql()'\n",
    "df.selectExpr(\"age >= 40 as older\", \"age\").show(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# your turn\n",
    "\n",
    "use spark.sql() to perform the following actions\n",
    "1. get the max and min cholesterol\n",
    "2. group by ChestPainType and get the mean Cholesterol\n",
    "3. how many incidents of each ChestPainType for each sex?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
