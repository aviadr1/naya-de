{"cells":[{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# change install_spark to True if you want to install spark on colab\n","install_spark = False\n","if install_spark:\n","    !apt-get update\n","    !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","    !wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n","    !tar xf spark-2.3.1-bin-hadoop2.7.tgz\n","    !pip install -q findspark\n","\n","    import os\n","    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","    os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.1-bin-hadoop2.7\"\n","\n","    import findspark\n","    findspark.init()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":584},"colab_type":"code","executionInfo":{"elapsed":41246,"status":"ok","timestamp":1563178273485,"user":{"displayName":"Naya College","photoUrl":"","userId":"00092338927245128733"},"user_tz":-180},"id":"UfU6c0U5rf3k","outputId":"a339646c-a480-4472-92e2-500ddb38c1b9"},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cnt7-naya-cdh63:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v2.4.3</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>pyspark-shell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f1b2c794ef0>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from pyspark import SparkContext\n","sc = SparkContext.getOrCreate()\n","\n","import pyspark\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.getOrCreate()\n","\n","spark"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"6l5tDY0RrVMn"},"source":["# Linear regression with pyspark"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{},"colab_type":"code","id":"PVmdjQQwrVMo"},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n","from pyspark.ml.regression import LinearRegression\n","from pyspark.ml.evaluation import RegressionEvaluator"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"RZKXjCNerVMs"},"source":["## Get the data"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"Q9duiizbrVMt"},"source":["It is easier (in this pyspark version) to first load the data as an RDD, and then modify it into a dataFrame. During this process we also remove the header using a combination of _zipWithIndex()_ and _filter()_ (taken from [here][1]). By looking at the file we see the \"schema\", which is used by the second _map()_.\n","\n","[1]: http://stackoverflow.com/a/31798247/3121900"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1c5VscgjK_NZbyxYcxTeJ6g4vGT93ZE5g\n","To: /home/naya/notebooks/07_ml/Big data science with SparkML/02 - Linear regression/weight.txt\n","100%|██████████| 16.6k/16.6k [00:00<00:00, 19.7MB/s]\n"]},{"data":{"text/plain":["'weight.txt'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["!pip install -qq gdown\n","import gdown\n","gdown.download('https://drive.google.com/file/d/1c5VscgjK_NZbyxYcxTeJ6g4vGT93ZE5g/view?usp=share_link', fuzzy=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"colab_type":"code","executionInfo":{"elapsed":1445,"status":"error","timestamp":1563178280899,"user":{"displayName":"Naya College","photoUrl":"","userId":"00092338927245128733"},"user_tz":-180},"id":"cSnjQuKRrVMu","outputId":"467528f6-d4b8-4f7b-d891-cc847d01edc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---+------+------+\n","|Sex|Age|Height|Weight|\n","+---+---+------+------+\n","|  f| 26| 171.1|  57.0|\n","|  m| 44| 180.1|  84.7|\n","|  m| 32| 161.9|  73.6|\n","|  m| 27| 176.5|  81.0|\n","|  f| 26| 167.3|  57.4|\n","+---+---+------+------+\n","only showing top 5 rows\n","\n"]}],"source":["from pathlib import Path\n","weight_filename = Path(\"weight.txt\").absolute()\n","weights = spark.read.csv('file://' + str(weight_filename), \n","                         header=True, inferSchema=True)\n","weights.show(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"F0fuoCdnrVMx"},"source":["We already know that the age has no part in the model, so we drop the column."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"3-ErAtrbrVMy"},"outputs":[],"source":["weights = weights.drop('Age')\n","weights.show(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"L_z1dhNDrVM1"},"source":["We will illustrate the basics with the boys data and then repeat the process for the girls."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"tqGK4gWQrVM2"},"outputs":[],"source":["boys = weights.where(weights.Sex == 'm')\n","boys.show(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"aAwQPeKSrVM5"},"source":["### Vectorizing"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"rnByS3FnrVM6"},"source":["While Spark DataFrames were designed to facilitate table-oriented tasks, they are not optimized for the mathematical manipulations required for applying the machine learnign algorithms. To overcome this problem, Spark offers another data structure called **Vector**, which is a list-like data structure.\n","\n","Its role will be more clear later, but for now we can think of it as a special column, collecting together several not-necessarily-the-same-type columns. Vectors can be created by constructors from the _pyspark.ml.linalg_ module, but they can also be created by assembling existing columns with the [_VectorAssembler_][va] transformer.\n","\n","[va]: http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.feature.VectorAssembler \"VectorAssembler() API\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"TMMcXWqYrVM7"},"outputs":[],"source":["va = VectorAssembler(inputCols=['Height'], outputCol='features')\n","print type(va)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"RhFo6wPQrVM-"},"outputs":[],"source":["boys = va.transform(boys)\n","boys.show(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"sqHseY9frVND"},"source":["### Splitting the data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"RrbqcXcIrVNE"},"outputs":[],"source":["train_boys, test_boys = boys.randomSplit([0.7, 0.3], seed=1234)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"RZnrtuw5rVNI"},"source":["## Single variable"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"hKarLJAvrVNJ"},"source":["### Instantiate the model"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"b2KQYuDhrVNK"},"source":["The model itself is embodied by the [LinearRegression][1] **estimator** class. The initialization of the estimator requires the declaration of the features by the argument _featuresCol_, the target by the argument _labelCol_ and the future prediction column by the argument _predictionCol_. It does **NOT** require the data itself...\n","\n","[1]: https://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.regression.LinearRegression \"LinearRegression API\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"QdMypaKzrVNL"},"outputs":[],"source":["boys_lr = LinearRegression(featuresCol='features', \n","                           labelCol='Weight', \n","                           predictionCol='predicted weight')\n","print type(boys_lr)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"_YzuDYfurVNQ"},"source":["### Fit the model"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"U7-lChw8rVNR"},"source":["Being an **estimator**, a _LinearRegression_ object has a **_fit()_** method. This method applies the linear regression algorithm to fit the data in _featureCol_ to the labels in _labelCol_ to create a **model**, which is a type of **transformer**."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"5LvLdGvWrVNS"},"outputs":[],"source":["boys_lm = boys_lr.fit(train_boys)\n","print type(boys_lm)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"RyU8V-GprVNY"},"source":["### Inspect the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"v6IbxV3TrVNZ"},"outputs":[],"source":["print boys_lm.coefficients\n","print boys_lm.intercept"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"mNdKigjnrVNg"},"source":["Being a **transformer**, a _LinearRegressionModel_ object has a **_transform()_** method. This is the equivalent of the _predict()_ method from scikit-learn, and it applies the applies the model to the data and creates a new column with the name _predictionCol_."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"V_84nuu2rVNh"},"outputs":[],"source":["train_boys = boys_lm.transform(train_boys)\n","train_boys.show(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"mxQMtFYhrVNk"},"source":["### Assess the model"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"57mLMJzhrVNl"},"source":["The RMSE (and other measures) are available in the _pyspark.ml.evaluation_ module. As usual, we instantiate an evaluator object with the proper arguments, and then apply it to the data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"8mC9FewrrVNm"},"outputs":[],"source":["evaluator = RegressionEvaluator(predictionCol=\"predicted weight\", \n","                                labelCol=\"Weight\", \n","                                metricName=\"rmse\")\n","print evaluator.evaluate(train_boys)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"gk_WYg4LrVNp"},"source":["### Validate the model"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"EbM0yhxorVNq"},"source":["We apply the same steps to the test data ([pipeline][1], anyone?) and hope the results will be similar, otherwise we apparently have an overfitting problem.\n","\n","[1]: https://spark.apache.org/docs/2.0.2/ml-pipeline.html \"pipeline documentation\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"OjPsX-F8rVNs"},"outputs":[],"source":["test_boys = boys_lm.transform(test_boys)\n","print evaluator.evaluate(test_boys)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"95mc7xRfrVNz"},"source":["## Multiple variables"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"d6s6WeqWrVN0"},"source":["The process is exactly the same, so we will show the entire code without verbal explanations and review it to note the minor differences."]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"oCOZPysbrVN1"},"source":["### Get the data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"HvMy5_5hrVN3"},"outputs":[],"source":["diet = spark.read.csv(\"/FileStore/tables/gm30zbkj1490307234855/diet.txt\", \n","                      sep=';', header=True, inferSchema=True).drop('id')\n","\n","for col_name in diet.columns:\n","  diet = diet.withColumnRenamed(col_name, col_name.replace('.', '_'))\n","  \n","diet.show(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"Y28RRjGmrVN6"},"source":["> **NOTE:** Spark does not allow features to have a dot (.) in their name."]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"t-2jTxZ7rVN7"},"source":["#### Vectorizing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"7yOAnIgyrVOA"},"outputs":[],"source":["va = VectorAssembler(inputCols=diet.columns[:-1], outputCol='features')\n","diet = va.transform(diet)\n","diet.show(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"5m0abLQ2rVOD"},"source":["### Split the data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"GJp70mkmrVOF"},"outputs":[],"source":["train_diet, test_diet = diet.randomSplit([0.7, 0.3], seed=1729)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"l9auGwa_rVOK"},"source":["### Instantiate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"1VV0VEr2rVOM"},"outputs":[],"source":["diet_lr = LinearRegression(featuresCol='features', \n","                           labelCol='change_kg', \n","                           predictionCol='predicted change')"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"YHbpRj4zrVOR"},"source":["### Fit the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"7wKT_VLarVOT"},"outputs":[],"source":["diet_lm = diet_lr.fit(train_diet)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"cUcjLN4mrVOV"},"source":["### Inspect the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"5tiayG-WrVOW"},"outputs":[],"source":["print diet_lm.coefficients\n","print diet_lm.intercept"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"4MLCs_m5rVOZ"},"source":["### Apply the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"9ygvB6p0rVOa"},"outputs":[],"source":["train_diet = diet_lm.transform(train_diet)\n","train_diet.show(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"oDRzo6RerVOe"},"source":["### Assess the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"RRzGj6dTrVOf"},"outputs":[],"source":["evaluator = RegressionEvaluator(predictionCol=\"predicted change\", \n","                                labelCol=\"change_kg\", \n","                                metricName=\"rmse\")\n","print evaluator.evaluate(train_diet)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"7hIodHy7rVOi"},"source":["### Validate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"8imRTjdBrVOj"},"outputs":[],"source":["test_diet = diet_lm.transform(test_diet)\n","print evaluator.evaluate(test_diet)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"c0Vr_1QhrVOm"},"source":["> **Your turn 1:** Read the grades.txt file. For the sake of this exercise you may ignore the splitting step and use the entire data for the regression.\n","\n","> * Part I - Fit three single-variable regression models for the SAT grade based on each of the math grade, the english grade and the literature grade, and analyze them. Which of the models is the best?\n","> * Part II - Fit a new linear regression model with all three grades as predictors, and analyze the model. Is the new model better than the previous ones?"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"MM9i7XuarVOn"},"source":["## Dummy variables"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"Q2HFmjPxrVOo"},"source":["The concept of dummy variables is implemented in _pyspark.ml_ by a combination of two optional **estimators and transformers** - [_StringIndexer_][1] and [_OneHotEncoder_][2]. _StringIndexer_ maps a \"categorical\" feature column of type string into arbitrary integers, and _OneHotEncoder_ maps a column of category indices to a column of binary vectors, with at most a single one-value per row that indicates the input category index. It sounds complicated, but it is not...\n","\n","More generally, the module [_features_][3] of _pyspark.ml_ supports a large family of data transformers, which are documented [here][4].\n","\n","[1]: https://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.feature.StringIndexer \"StringIndexer API\"\n","[2]: https://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.feature.OneHotEncoder \"OneHotEncoder API\"\n","[3]: https://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#module-pyspark.ml.feature \"ml.features API\"\n","[4]: https://spark.apache.org/docs/2.0.2/ml-features.html \"ml.features documentation\""]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"7pXZDuR5rVOp"},"source":["To apply this concept to the _gender_ feature we roll back to the step before the vectorizing. This time we consider both boys and girls."]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"hXBcLrtQrVOp"},"source":["#### Indexing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"iterLW6arVOu"},"outputs":[],"source":["si = StringIndexer(inputCol='Sex', outputCol='Sex (indexed)')\n","si_model = si.fit(weights)\n","weights = si_model.transform(weights)\n","weights.show(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"3qP0yHYkrVOy"},"source":["#### Encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"TvLSwPhFrVOz"},"outputs":[],"source":["ohe = OneHotEncoder(inputCol='Sex (indexed)', outputCol='Sex (one hot)')\n","ohe.setDropLast(False)\n","weights = ohe.transform(weights)\n","weights.show(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"dsn97KC9rVO1"},"source":["> **NOTE:** _OneHotEncoder()_ returns [sparse vectors][1], which is a standard representation of arrays with a lot of zeroes. In this representation, the tuple (_n_, [_locs_], [_vals_]) means there are _n_ elements in the vector, and the value in location _locs[i]_ is _vals[i]_. This makes the illustration not very intuitive, but we will have to deal with that...\n","\n","[1]: https://en.wikipedia.org/wiki/Sparse_array \"Sparse array - Wikipedia\""]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"bLGhHolurVO2"},"source":["#### Vectorizing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"x1nicCfurVO3"},"outputs":[],"source":["va = VectorAssembler(inputCols=['Height', 'Sex (one hot)'], outputCol='features')\n","weights = va.transform(weights)\n","weights.show(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"4x_5EMw0rVO5"},"source":["### Split the data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"I7FJAO7UrVO6"},"outputs":[],"source":["train_weights, test_weights = weights.randomSplit([0.7, 0.3], seed=8128)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"WlswXVO6rVO8"},"source":["### Instantiate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"TgVBQZ-0rVO9"},"outputs":[],"source":["weight_lr = LinearRegression(featuresCol='features', \n","                             labelCol='Weight', \n","                             predictionCol='predicted weight',\n","                             solver='bfgs')"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"MdFC2g96rVPD"},"source":["> **NOTE:** For a reason not clear to me thee default linear regression does not work properly, and I had to specifically state the BFGS algorithm."]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"kQx5v3CGrVPE"},"source":["### Fit the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"5HhHhxbirVPG"},"outputs":[],"source":["weight_lm = weight_lr.fit(weights)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"_GVLdgB1rVPL"},"source":["### Inspect the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"YZa-FmI5rVPM"},"outputs":[],"source":["print weight_lm.coefficients\n","print weight_lm.intercept"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"-2VLsiSWrVPP"},"source":["### Apply the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"bi4q86wvrVPP"},"outputs":[],"source":["train_weights = weight_lm.transform(train_weights)\n","train_weights.show(5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"WB_GBRb4rVPU"},"source":["### Assess the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"sfnCY2w6rVPV"},"outputs":[],"source":["evaluator = RegressionEvaluator(predictionCol=\"predicted weight\", \n","                                labelCol=\"Weight\", \n","                                metricName=\"rmse\")\n","print evaluator.evaluate(train_weights)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"xQ9OiEPurVPY"},"source":["### Validate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","collapsed":true,"id":"rUU822oHrVPY"},"outputs":[],"source":["test_weights = weight_lm.transform(test_weights)\n","print evaluator.evaluate(test_weights)"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"6HODWLIMrVPd"},"source":["> **Your turn 2:** The file prices.csv contains rental details for many apartments in several cities. Read the file, use its data to create two linear models for estimating the price (part I and part II below), and explain which one is better and why.\n","\n","> * Part I - The ‘Rooms’ feature is an integer.\n","> * Part II - The ‘Rooms’ feature is a dummy variables."]}],"metadata":{"colab":{"name":"Linear regression with pyspark.ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":0}
