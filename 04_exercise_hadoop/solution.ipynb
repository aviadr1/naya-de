{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "In this exercise we will upload the audiostore database from MySQL to Impala. We will do it in the following steps:\n",
    "\n",
    "1. Locate/create the database in MySQL\n",
    "2. Create/clean the staging folder in HDFS\n",
    "3. Make the list of tables in the database\n",
    "4. Upload the tables to the staging folder as Parquet files\n",
    "5. Load the data into Impala\n",
    "6. Query your data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "> Make sure you have the audiostore database in MySQL\n",
    "\n",
    "use `import os` and `os.system` to run cli commands to create a database and run the audiostoreDB.sql script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blah\n",
      "mysql: [Warning] Using a password on the command line interface can be insecure.\n",
      "+--------------------+\n",
      "| Database           |\n",
      "+--------------------+\n",
      "| information_schema |\n",
      "| amon               |\n",
      "| audiostore         |\n",
      "| classicmodels      |\n",
      "| hue                |\n",
      "| metastore          |\n",
      "| mysql              |\n",
      "| nav                |\n",
      "| navms              |\n",
      "| oozie              |\n",
      "| performance_schema |\n",
      "| rman               |\n",
      "| scm                |\n",
      "| sentry             |\n",
      "| sys                |\n",
      "+--------------------+\n",
      "mysql: [Warning] Using a password on the command line interface can be insecure.\n",
      "mysql: [Warning] Using a password on the command line interface can be insecure.\n",
      "mysql: [Warning] Using a password on the command line interface can be insecure.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# os.system('echo blah')\n",
    "!echo blah\n",
    "\n",
    "# os.system(\"mysql -unaya -pNayaPass1!  -e 'show databases;' \")\n",
    "!mysql -unaya -pNayaPass1!  -e 'show databases;' \n",
    "\n",
    "# # drop database if exists\n",
    "# os.system(\"sudo mysql -unaya -pNayaPass1!  -e 'DROP DATABASE IF EXISTS audiostore;' \")\n",
    "!sudo mysql -unaya -pNayaPass1!  -e 'DROP DATABASE IF EXISTS audiostore;'\n",
    "\n",
    "# # create database audiostore\n",
    "# os.system(\"sudo mysql -unaya -pNayaPass1!  -e 'create database audiostore;' \")\n",
    "!sudo mysql -unaya -pNayaPass1!  -e 'create database audiostore;'\n",
    "\n",
    "# run databases.sql\n",
    "# os.system(\"sudo mysql -unaya -pNayaPass1!  audiostore<AudioStoreDB.sql \")\n",
    "!sudo mysql -unaya -pNayaPass1!  audiostore<AudioStoreDB.sql\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part 2 \n",
    "We are going to use the temporary folder /tmp/staging/ for storing the tables before we upload them into\n",
    "HDFS. Make sure this folder exists (if not - create it) and that it is empty.\n",
    "\n",
    "\n",
    "- Use pyarrow to create a HadoopFileSystem instance (usually called fs) to control HDFS functionalities.\n",
    "- Use simple Python scripting with the exists(), mkdir() and delete() methods.\n",
    "\n",
    "dont forget `import pyarrow as pa` or altenatively, use the file `hadoop_config.py` where we have all the definitions by using `import hadoop_config` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyarrow as pa\n",
    "from hadoop_config import fs, mysql_cnx, hdfs, client as impala_client, hive_cnx\n",
    "\n",
    "# fs = pa.hdfs.HadoopFileSystem(\n",
    "#     host='Cnt7-naya-cdh63', #or internal-ip\n",
    "#     port=8020,\n",
    "#     user='hdfs',\n",
    "#     kerb_ticket=None,\n",
    "#     extra_conf=None)\n",
    "\n",
    "if fs.exists('/tmp/staging'):\n",
    "    fs.delete('/tmp/staging', recursive=True)\n",
    "fs.mkdir('/tmp/staging', recursive=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "In this  step we would like to iterate the tables in\n",
    "order to upload them as Parquet files, so in this step you should get the list of tables in the database.\n",
    "\n",
    "- Use any RDBMS API to connect to the database. SQLAlchemy is a good option, but consider using a MySQL connector (like the official PyMySQL, which is already installed (explained better at W3Schools).\n",
    "- Execute an SQL query to get all the names of the tables in the database, and then use the fetchall() method to turn the result into a list.\n",
    "\n",
    "remember the file `hadoop_config.py` already contains all the definitions we need so do `from hadoop_config import cnx as mysql_cnx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tables_in_audiostore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>employee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>invoiceline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mediatype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>playlisttrack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tables_in_audiostore\n",
       "0                 album\n",
       "1                artist\n",
       "2              customer\n",
       "3              employee\n",
       "4                 genre\n",
       "5               invoice\n",
       "6           invoiceline\n",
       "7             mediatype\n",
       "8              playlist\n",
       "9         playlisttrack\n",
       "10                track"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tables = pd.read_sql(\"SHOW TABLES\", mysql_cnx)\n",
    "tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4\n",
    "\n",
    "Import all the tables from the audiostore database into the staging folder using the Parquet format.\n",
    "\n",
    "\n",
    "- There is going to be a for-loop on the list of tables. Each table will be converted to a Parquet file, which will be uploaded to our HDFS staging area.\n",
    "- I couldn't find a direct option to make this transition, so I've added an intermediate staging step through pandas.DataFrame. Since pandas is so popular, it is easier to first read the tables as pandas.DataFrame (using read_sql()) and then write them as Parquet (using write_table()).\n",
    "- Parquet does not support complex datetime types, so you might have to manipulate your data so that Parquet will \"eat it\".\n",
    "- Parquet files have no standard encoding, so you should consider them as a stream of binary files.\n",
    "\n",
    "these imports are useful\n",
    "```\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "album\n",
      "\t chunk 0\n",
      "artist\n",
      "\t chunk 0\n",
      "customer\n",
      "\t chunk 0\n",
      "employee\n",
      "\t chunk 0\n",
      "genre\n",
      "\t chunk 0\n",
      "invoice\n",
      "\t chunk 0\n",
      "invoiceline\n",
      "\t chunk 0\n",
      "\t chunk 1\n",
      "\t chunk 2\n",
      "mediatype\n",
      "\t chunk 0\n",
      "playlist\n",
      "\t chunk 0\n",
      "playlisttrack\n",
      "\t chunk 0\n",
      "\t chunk 1\n",
      "\t chunk 2\n",
      "\t chunk 3\n",
      "\t chunk 4\n",
      "\t chunk 5\n",
      "\t chunk 6\n",
      "\t chunk 7\n",
      "\t chunk 8\n",
      "track\n",
      "\t chunk 0\n",
      "\t chunk 1\n",
      "\t chunk 2\n",
      "\t chunk 3\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "batch_size = 1000\n",
    "for table in tables.squeeze().to_list():\n",
    "    print(table)\n",
    "    path_table = '/tmp/staging/' + table + '.parquet'\n",
    "    with fs.open(path_table, \"wb\") as fw:\n",
    "        for i, chunk_df in enumerate(pd.read_sql(f\"SELECT * FROM {table}\", mysql_cnx, chunksize=batch_size)):\n",
    "            print(f\"\\t chunk {i}\")\n",
    "            df_for_hdfs = pa.Table.from_pandas(chunk_df)\n",
    "            pq.write_table(df_for_hdfs, fw)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5\n",
    " In order for Impala to query these tables, one has to\n",
    "define them as a database. Create a new database called my_audiostore at `/user/hive/warehouse/` and load the data\n",
    "from the staging folder into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stg = '/tmp/staging/'\n",
    "impala_path = '/user/hive/warehouse/audiostore/'\n",
    "fs.chown(impala_path, group='naya', owner='impala')\n",
    "\n",
    "impala_client.create_database('audiostore',path=impala_path,force=True)\n",
    "impala_client.set_database('audiostore')\n",
    "impala_client.raw_sql('INVALIDATE METADATA', results=False)\n",
    "#INVALIDATE METADATA Statement\n",
    "#https://impala.apache.org/docs/build/html/topics/impala_invalidate_metadata.html\n",
    "\n",
    "tables = pd.read_sql(\"SHOW TABLES\", mysql_cnx).squeeze().to_list()  # the mysql tables\n",
    "for table in tables:\n",
    "    print(\"starting \",table , end=\"...\")\n",
    "    #change dir owner\n",
    "    fs.chown(stg, group='naya',owner='impala')\n",
    "    \n",
    "    #create tables in impala- only schema first\n",
    "    pf = impala_client.parquet_file(hdfs_dir = f'{stg}', like_file = f'{stg}{table}.parquet')\n",
    "    impala_client.create_table(table,\n",
    "                        schema=pf.schema(),\n",
    "                        database='audiostore',\n",
    "                        external=True,\n",
    "                        force=True,\n",
    "                        format='parquet',\n",
    "                        location=f'{impala_path}{table}.parquet',\n",
    "                        like_parquet=None)\n",
    "\n",
    "    impala_client.raw_sql('INVALIDATE METADATA', results=False)\n",
    "    #5. Load the data into Impala\n",
    "    impala_client.load_data(table_name =table,\n",
    "                     path = f'{stg}{table}.parquet',\n",
    "                     database='audiostore',\n",
    "                     overwrite=True, partition=None\n",
    "                    )\n",
    "    print(\"finish\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tables_in_audiostore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>album</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>employee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>invoiceline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mediatype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>playlist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>playlisttrack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>track</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tables_in_audiostore\n",
       "0                 album\n",
       "1                artist\n",
       "2              customer\n",
       "3              employee\n",
       "4                 genre\n",
       "5               invoice\n",
       "6           invoiceline\n",
       "7             mediatype\n",
       "8              playlist\n",
       "9         playlisttrack\n",
       "10                track"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
